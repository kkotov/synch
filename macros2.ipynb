{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"./sales_train.csv.gz\")\n",
    "test_df  = pd.read_csv(\"./test.csv.gz\")\n",
    "\n",
    "categories = pd.read_csv('./item_categories.csv')\n",
    "items = pd.read_csv('./items.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build scafold grid indexed by all combinatinos of shops and items observed every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# create grid of all possible shops and items remembered to be sold there\n",
    "grid = []\n",
    "for date_block_num in train_df[\"date_block_num\"].unique():\n",
    "    all_item_ids = train_df[train_df.date_block_num==date_block_num][\"item_id\"].unique()\n",
    "    all_shop_ids = train_df[train_df.date_block_num==date_block_num][\"shop_id\"].unique()\n",
    "    grid.append( np.array(list(product(*[all_item_ids, all_shop_ids, [date_block_num]]))) )\n",
    "\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = [\"item_id\", \"shop_id\", \"date_block_num\"], dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the grid with counts of monthly sales from the training set and clip those to 20 as suggested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = train_df.groupby([\"item_id\", \"shop_id\", \"date_block_num\"], as_index=False).agg({\"item_cnt_day\":\"sum\"})\n",
    "\n",
    "agg.columns = [\"item_id\", \"shop_id\", \"date_block_num\", \"target\"] # this is all that all_data will have for now!\n",
    "\n",
    "all_data = pd.merge(grid, agg, how=\"left\", on=[\"item_id\", \"shop_id\", \"date_block_num\"])\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)\n",
    "\n",
    "all_data['date_block_num'] = all_data['date_block_num'].astype(np.int8)\n",
    "all_data['shop_id'] = all_data['shop_id'].astype(np.int8)\n",
    "all_data['item_id'] = all_data['item_id'].astype(np.int16)\n",
    "\n",
    "all_data['target'] = (all_data['target']\n",
    "                      .fillna(0)\n",
    "                      .clip(0,20)\n",
    "                      .astype(np.float16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the data frame to the target month usgin shop/item combinations of interest from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['date_block_num'] = 34\n",
    "test_df['target'] = 0.\n",
    "test_df['date_block_num'] = test_df['date_block_num'].astype(np.int8)\n",
    "test_df['shop_id'] = test_df['shop_id'].astype(np.int8)\n",
    "test_df['item_id'] = test_df['item_id'].astype(np.int16)\n",
    "all_data = pd.concat([all_data, test_df[['date_block_num','shop_id','item_id','target']]],\n",
    "                     ignore_index=True,\n",
    "                     sort=False,\n",
    "                     keys=['date_block_num','shop_id','item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categories['split'] = categories['item_category_name'].str.split('-')\n",
    "categories['type'] = categories['split'].map(lambda x: x[0].strip())\n",
    "categories['type_code'] = LabelEncoder().fit_transform(categories['type'])\n",
    "\n",
    "categories['subtype'] = categories['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "categories['subtype_code'] = LabelEncoder().fit_transform(categories['subtype'])\n",
    "categories = categories[['item_category_id','type_code', 'subtype_code']]\n",
    "\n",
    "items = pd.merge(categories, items, how=\"right\", on=[\"item_category_id\"])\n",
    "\n",
    "all_data = pd.merge(all_data, items, how='left', on=['item_id'])\n",
    "all_data['item_category_id'] = all_data['item_category_id'].astype(np.int8)\n",
    "all_data['type_code'] = all_data['type_code'].astype(np.int8)\n",
    "all_data['subtype_code'] = all_data['subtype_code'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce mean encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, as long as month (\"date_block_num\") is in the groupby list, month #34 doesn't affect the means\n",
    "def add_encoded_target_mean(data, groupby, name):\n",
    "    aggregated_sales = data.groupby(groupby).target.mean()\n",
    "    aggregated_sales.name = name\n",
    "    return data.merge(aggregated_sales.reset_index(), how = \"left\", on = groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total sales for a month\n",
    "all_data = add_encoded_target_mean(all_data, [\"date_block_num\"], \"total_monthly_sales\")\n",
    "\n",
    "# total sales for a month per shop\n",
    "all_data = add_encoded_target_mean(all_data, [\"date_block_num\", \"shop_id\"], \"total_monthly_shop_sales\")\n",
    "\n",
    "# total sales for a month per item\n",
    "all_data = add_encoded_target_mean(all_data, [\"date_block_num\", \"item_id\"], \"total_monthly_item_sales\")\n",
    "\n",
    "# total sales for a month per category\n",
    "all_data = add_encoded_target_mean(all_data, [\"date_block_num\", \"item_category_id\"], \"total_monthly_category_sales\")\n",
    "\n",
    "# total sales for a month per supercategory\n",
    "all_data = add_encoded_target_mean(all_data, [\"date_block_num\", \"type_code\"], \"total_monthly_supercategory_sales\")\n",
    "\n",
    "# total sales for a month per subcategory\n",
    "all_data = add_encoded_target_mean(all_data, [\"date_block_num\", \"subtype_code\"], \"total_monthly_subcategory_sales\")\n",
    "\n",
    "# total sales for a month per category in a shop\n",
    "all_data = add_encoded_target_mean(all_data, [\"date_block_num\", \"item_category_id\", \"shop_id\"], \"total_monthly_shop_category_sales\")\n",
    "\n",
    "# total sales for a month per supercategory in a shop\n",
    "all_data = add_encoded_target_mean(all_data, [\"date_block_num\", \"type_code\", \"shop_id\"], \"total_monthly_shop_supercategory_sales\")\n",
    "\n",
    "# total sales for a month per subcategory in a shop\n",
    "all_data = add_encoded_target_mean(all_data, [\"date_block_num\", \"subtype_code\", \"shop_id\"], \"total_monthly_shop_subcategory_sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_lags(data, lags, columns):\n",
    "    index = [\"date_block_num\", \"shop_id\", \"item_id\"]\n",
    "    lagged_data = []\n",
    "    for l in lags:\n",
    "        lag = data[index + columns].copy()\n",
    "        lag.columns = index + [col+\"_lag_\"+str(l) for col in columns]\n",
    "        lag[\"date_block_num\"] += l\n",
    "        lagged_data.append(lag)\n",
    "\n",
    "    if not lags:\n",
    "        return data[[\"date_block_num\"]]\n",
    "    \n",
    "    retval = lagged_data.pop()\n",
    "\n",
    "    for l in lagged_data:\n",
    "        retval = pd.merge(retval, l, how='left', on=index)\n",
    "\n",
    "    return retval.fillna(0) # non-existing lags are set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_lags = construct_lags(all_data, [1,2,3,6,12], [\"target\"])\n",
    "\n",
    "mean_lags = construct_lags(all_data,\n",
    "                          [1],\n",
    "                          [\"total_monthly_sales\",\n",
    "                           \"total_monthly_shop_sales\",\n",
    "                           \"total_monthly_item_sales\",\n",
    "                           \"total_monthly_category_sales\",\n",
    "                           \"total_monthly_supercategory_sales\",\n",
    "                           \"total_monthly_subcategory_sales\",\n",
    "                           \"total_monthly_shop_category_sales\",\n",
    "                           \"total_monthly_shop_supercategory_sales\",\n",
    "                           \"total_monthly_shop_subcategory_sales\"\n",
    "                          ])\n",
    "\n",
    "all_data = pd.merge(all_data, trg_lags,  how='left', on=['date_block_num','shop_id','item_id'])\n",
    "all_data = pd.merge(all_data, mean_lags, how='left', on=['date_block_num','shop_id','item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = all_data[(all_data.date_block_num>12)&(all_data.date_block_num<34)].fillna(0)\n",
    "\n",
    "predictors = [\n",
    "    \"target_lag_1\",\n",
    "    \"target_lag_2\",\n",
    "    \"target_lag_3\",\n",
    "    \"target_lag_6\",\n",
    "    \"target_lag_12\",\n",
    "    \"total_monthly_sales_lag_1\",\n",
    "    \"total_monthly_shop_sales_lag_1\",\n",
    "    \"total_monthly_item_sales_lag_1\",\n",
    "    \"total_monthly_category_sales_lag_1\",\n",
    "    \"total_monthly_supercategory_sales_lag_1\",\n",
    "    \"total_monthly_subcategory_sales_lag_1\",\n",
    "    \"total_monthly_shop_category_sales_lag_1\",\n",
    "    \"total_monthly_shop_supercategory_sales_lag_1\",    \n",
    "    \"total_monthly_shop_subcategory_sales_lag_1\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(train[predictors], train.target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dac41a5f2613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"model2.rf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#model2 = RandomForestRegressor(n_estimators=64, max_features=3, n_jobs=6) #len(predictors)/2\n",
    "#model2.fit(X_train, y_train)\n",
    "\n",
    "from joblib import dump, load\n",
    "joblib.dump(model2,\"model2.joblib\")\n",
    "\n",
    "ypred = model2.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, ypred))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 43s, sys: 23.4 s, total: 32min 6s\n",
      "Wall time: 8min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=3, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=6,\n",
       "                      oob_score=False, random_state=None, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "full_model = RandomForestRegressor(n_estimators=64, max_features=3, n_jobs=6) #len(predictors)/2\n",
    "full_model.fit(train[predictors], train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                              score\n",
      "total_monthly_item_sales_lag_1                0.381233\n",
      "total_monthly_shop_category_sales_lag_1       0.0994527\n",
      "total_monthly_shop_subcategory_sales_lag_1    0.0849444\n",
      "target_lag_1                                  0.0674132\n",
      "total_monthly_shop_sales_lag_1                0.0553516\n",
      "total_monthly_shop_supercategory_sales_lag_1  0.0519963\n",
      "total_monthly_category_sales_lag_1            0.0509722\n",
      "target_lag_2                                  0.0423134\n",
      "total_monthly_subcategory_sales_lag_1         0.0386334\n",
      "total_monthly_supercategory_sales_lag_1       0.031973\n",
      "target_lag_3                                  0.0281671\n",
      "target_lag_6                                  0.0248578\n",
      "total_monthly_sales_lag_1                     0.0233411\n",
      "target_lag_12                                 0.0193503\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "headers = [\"name\", \"score\"]\n",
    "values = sorted(zip(X_test.columns, full_model.feature_importances_), key=lambda x: x[1] * -1)\n",
    "print(tabulate(values, headers, tablefmt=\"plain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_34 = all_data[all_data.date_block_num == 34].fillna(0)\n",
    "month_34['item_cnt_month'] = full_model.predict(month_34[predictors])\n",
    "test = pd.merge(test_df,month_34, on=[\"shop_id\",\"item_id\"]).fillna(0)\n",
    "\n",
    "test = test.loc[:,['ID', 'item_cnt_month']]\n",
    "test.set_index(\"ID\", inplace=True)\n",
    "test[\"item_cnt_month\"] = test[\"item_cnt_month\"].round().astype(\"int64\")\n",
    "\n",
    "test[test.item_cnt_month>20] = 20\n",
    "test.to_csv(\"macro2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro -q __prepare_data 2-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored '__prepare_data' (Macro)\n"
     ]
    }
   ],
   "source": [
    "%store __prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
